{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import requests\n",
    "import json\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from numpy import ones,vstack\n",
    "from numpy.linalg import lstsq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% imports\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "provider = \"github\"\n",
    "nodes = ['pulls', 'issues', 'commits']\n",
    "save_node = \"repositoryStats\"\n",
    "# nodes = ['pulls', 'issues']\n",
    "start_date = '2017-09-01T00:00:00-03:00'\n",
    "end_date = '2021-09-15T23:59:59-03:00'\n",
    "\n",
    "date_format = '%Y-%m-%dT%H:%M:%S%z'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% params\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def save_data(_provider, _data_api_params):\n",
    "    _data_api_url = f'http://githunter-bind-starws.labbs.com.br/publish/provider/'+ _provider + '/node/' + save_node + '?createRawData=true'\n",
    "    _data_api_headers = {\n",
    "        'content-type': 'application/json'\n",
    "    }\n",
    "    _data_api_request = requests.post(_data_api_url, json=_data_api_params, headers=_data_api_headers)\n",
    "    _data = json.loads(_data_api_request.text)\n",
    "    return _data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% save data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def load_data(_provider, _node, _start_date, _end_date):\n",
    "    _data_api_url = f'http://githunter-bind-starws.labbs.com.br/metrics'\n",
    "    _data_api_params = {\n",
    "        'startDateTime': _start_date,\n",
    "        'endDateTime': _end_date,\n",
    "        'provider': _provider,\n",
    "        'node': _node\n",
    "    }\n",
    "    _data_api_headers = {\n",
    "        'content-type': 'application/json'\n",
    "    }\n",
    "    _data_api_request = requests.get(_data_api_url, params=_data_api_params, headers=_data_api_headers)\n",
    "\n",
    "    if not _data_api_request:\n",
    "        print('No data found in StarWS')\n",
    "        return None\n",
    "    else:\n",
    "        _data = json.loads(_data_api_request.text)['data']\n",
    "        # data_source = json.dumps(data, indent=4, sort_keys=True)\n",
    "        return _data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% request data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def load_mongo_data(_repo_list):\n",
    "    _data_api_url = f'http://localhost:3333/code-info'\n",
    "    _data_api_params = {\n",
    "        'repoList': _repo_list\n",
    "    }\n",
    "    _data_api_headers = {\n",
    "        'content-type': 'application/json'\n",
    "    }\n",
    "    _data_api_request = requests.get(_data_api_url, json=_data_api_params, headers=_data_api_headers)\n",
    "    _data = json.loads(_data_api_request.text)\n",
    "    # _data_source = json.dumps(_data, indent=4, sort_keys=True)\n",
    "    if 'data' in _data:\n",
    "        return _data['data']\n",
    "    elif 'repositories' in _data:\n",
    "        return _data['repositories']\n",
    "    return _data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% request Mongo data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    # frequency\n",
    "    \"commitFrequency\": [[366,0], [168,40], [48,60], [6,100]],\n",
    "    \"issuesRecent\": [[720,0],[360,20],[160,50],[48,80],[24,100]],\n",
    "    \"issuesGettingClosed\": [[720,0], [360,40], [160,80], [72,100]],\n",
    "    \"issuesClosedQuickly\": [[720,0], [504,40], [240,60], [120,100]],\n",
    "    \"issuesResponseQuickly\": [[336,0], [168,40], [48,50], [24,80],[2,100]],\n",
    "    \"pullsResponseQuickly\": [[336,0], [168,40], [48,50], [24,80],[2,100]],\n",
    "    \"pullsRecent\": [[720,0],[360,20],[160,50],[48,80],[24,100]],\n",
    "    \"pullsGettingMerged\": [[720,0], [360,40], [160,80], [72,100]],\n",
    "\n",
    "    #definition oos\n",
    "    \"readmeFileSize\": [[0,0], [3500,100]],\n",
    "\n",
    "    # popularity\n",
    "    \"numberOfContributors\": [[1,0], [50,30] ,[100,70], [200,100]],\n",
    "    \"numberOfIssues\": [[1,0], [50,30] ,[100,70], [200,100]],\n",
    "    \"numberOfPulls\": [[1,0], [50,30] ,[100,70], [200,100]]\n",
    "}\n",
    "\n",
    "def format_date(_date_string):\n",
    "    _date_obj = datetime.datetime.strptime(_date_string, date_format)\n",
    "    return _date_obj\n",
    "\n",
    "def average(_list):\n",
    "    if len(_list) > 0:\n",
    "        return sum(_list) / len(_list)\n",
    "    return 0\n",
    "\n",
    "def get_metric_percent(_metric, _value):\n",
    "    _btw_index = -1 # Last array position\n",
    "    for i, v in enumerate(metrics[_metric]):\n",
    "        if _value >= v[0]:\n",
    "            _btw_index = i\n",
    "            break\n",
    "    if _btw_index == 0:\n",
    "        return metrics[_metric][0][1] # returning minimal score\n",
    "    elif _btw_index == -1:\n",
    "        return metrics[_metric][-1][1] # returning maximal score\n",
    "\n",
    "    _point_0 = (metrics[_metric][i-1][0], metrics[_metric][i-1][1])\n",
    "    _point_1 = (metrics[_metric][i][0], metrics[_metric][i][1])\n",
    "    _points = [_point_0,_point_1]\n",
    "    _x_coords, _y_coords = zip(*_points)\n",
    "    _A = vstack([_x_coords,ones(len(_x_coords))]).T\n",
    "    _x, _c = lstsq(_A, _y_coords)[0]\n",
    "\n",
    "    _score = _x * _value + _c\n",
    "\n",
    "    return _score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Calculation Utils\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def calc_frequency(_list):\n",
    "#     sort by date\n",
    "#     print(_list)\n",
    "    if len(_list) == 0:\n",
    "        return 0\n",
    "    _frequency = 0\n",
    "    for index, value in enumerate(_list):\n",
    "        if index == 0:\n",
    "            _date_a = datetime.datetime.now().replace(tzinfo=datetime.timezone.utc).astimezone(tz=None)\n",
    "        else:\n",
    "            _date_a = format_date(_list[index-1][0])\n",
    "        _date_b = format_date(_list[index][0])\n",
    "        _delta = _date_a - _date_b\n",
    "        if _delta.total_seconds() < 0:\n",
    "            _delta = _date_b - _date_a\n",
    "        # print(\"Delta: \",_date_a, _date_b, _delta)\n",
    "        _frequency = _frequency + _delta.total_seconds()\n",
    "    _frequency = (_frequency/len(_list)) / 60 / 60\n",
    "    return _frequency\n",
    "\n",
    "def frequency_calc_score(_list, _metric):\n",
    "    _frequency = calc_frequency(_list)\n",
    "    _score = get_metric_percent(_metric, _frequency)\n",
    "    return _score\n",
    "\n",
    "def frequency_calc_score_close_time_issue(_list_of_dict):\n",
    "    _comments = _list_of_dict['comments.data']\n",
    "    _frequency = []\n",
    "    for _i, _c in _comments.items():\n",
    "        if not _c:\n",
    "            continue\n",
    "        _closed_at = _list_of_dict['closedAt'].get(_i)\n",
    "        _sorted = sorted(_c, key=lambda x: format_date(x['createdAt']), reverse=True)\n",
    "        for _s in _sorted:\n",
    "            _diff = format_date(_closed_at) - format_date(_s['createdAt'])\n",
    "            # sometime the user say thanks then close the issue\n",
    "            if _diff.total_seconds() >= 30:\n",
    "                break\n",
    "        _score = get_metric_percent('issuesClosedQuickly', (_diff.total_seconds() / 60 / 60))\n",
    "        _frequency.append(_score)\n",
    "    return average(_frequency)\n",
    "\n",
    "def frequency_calc_score_response_time_issue(_list_of_dict):\n",
    "    _comments = _list_of_dict['comments.data']\n",
    "    _frequency = []\n",
    "    for _i, _c in _comments.items():\n",
    "        if not _c:\n",
    "            continue\n",
    "        _created_at = _list_of_dict['createdAt'].get(_i)\n",
    "        _sorted = sorted(_c, key=lambda x: format_date(x['createdAt']))\n",
    "        for _s in _sorted:\n",
    "            _diff = format_date(_created_at) - format_date(_s['createdAt'])\n",
    "            # sometime the user say thanks then close the issue\n",
    "            if _diff.total_seconds() >= 30:\n",
    "                break\n",
    "        _score = get_metric_percent('issuesResponseQuickly', (_diff.total_seconds() / 60 / 60))\n",
    "        _frequency.append(_score)\n",
    "    return average(_frequency)\n",
    "\n",
    "def frequency_calc_score_response_time_pull(_list_of_dict):\n",
    "    _comments = _list_of_dict['comments.data']\n",
    "    _frequency = []\n",
    "    for _i, _c in _comments.items():\n",
    "        if not _c:\n",
    "            continue\n",
    "        _created_at = _list_of_dict['createdAt'].get(_i)\n",
    "        _sorted = sorted(_c, key=lambda x: format_date(x['createdAt']))\n",
    "        for _s in _sorted:\n",
    "            _diff = format_date(_created_at) - format_date(_s['createdAt'])\n",
    "            # sometime the user say thanks then close the issue\n",
    "            if _diff.total_seconds() >= 30:\n",
    "                break\n",
    "        _score = get_metric_percent('issuesResponseQuickly', (_diff.total_seconds() / 60 / 60))\n",
    "        _frequency.append(_score)\n",
    "    return average(_frequency)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Calculation Frequency Score\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def definition_oos_calc(_repo):\n",
    "    _definitionOSS = []\n",
    "\n",
    "    # Does it have a license?\n",
    "    if _repo['licenseInfo'] != \"\":\n",
    "        _definitionOSS.append(100)\n",
    "    else:\n",
    "        _definitionOSS.append(0)\n",
    "\n",
    "    # Does it have a Readme? Check the size (reference size repo Docker)\n",
    "    if _repo['hasReadmeFile']:\n",
    "        _score = 100\n",
    "        if not numpy.isnan(_repo['readmeFileSize']):\n",
    "            _score = get_metric_percent(\"readmeFileSize\", _repo['readmeFileSize'])\n",
    "        _definitionOSS.append(_score)\n",
    "    else:\n",
    "        _definitionOSS.append(0)\n",
    "\n",
    "    # Does it have a Contribution?\n",
    "    if _repo['hasContributingFile']:\n",
    "        _definitionOSS.append(70)\n",
    "    else:\n",
    "        _definitionOSS.append(30)\n",
    "\n",
    "    # Does it have a Code of Conduct?\n",
    "    if _repo['hasCodeOfConductFile']:\n",
    "        _definitionOSS.append(70)\n",
    "    else:\n",
    "        _definitionOSS.append(30)\n",
    "\n",
    "    return average(_definitionOSS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Calculation Definition OOS Score\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def popularity_calc_contribution(_qty):\n",
    "    _score = get_metric_percent(\"numberOfContributors\", _qty)\n",
    "    return _score\n",
    "\n",
    "def popularity_calc_issues(_qty):\n",
    "    _score = get_metric_percent(\"numberOfIssues\", _qty)\n",
    "    return _score\n",
    "\n",
    "def popularity_calc_pulls(_qty):\n",
    "    _score = get_metric_percent(\"numberOfPulls\", _qty)\n",
    "    return _score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Calculation Popularity Score\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulls\n",
      "issues\n",
      "commits\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for node in nodes:\n",
    "    raw_data = load_data(provider, node, start_date, end_date)\n",
    "    # Keeping last version of itens\n",
    "    if raw_data:\n",
    "        if node in 'commits':\n",
    "            data[node] = pd.DataFrame.from_dict(pd.json_normalize(raw_data))\n",
    "        else:\n",
    "            data[node] = pd.DataFrame.from_dict(pd.json_normalize(raw_data)).sort_values('dateTime').groupby('number').tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% StarWS Data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Getting owner and name from all nodes to request data from Mongo\n",
    "frames = []\n",
    "for k in data:\n",
    "    frames.append(data[k][['owner', 'name']])\n",
    "\n",
    "if frames:\n",
    "    result = pd.concat(frames).drop_duplicates().to_json(orient=\"table\", index=None)\n",
    "    repoList = json.loads(result)['data']\n",
    "\n",
    "    if repoList:\n",
    "        code_data = load_mongo_data(repoList)\n",
    "        data['code'] = pd.DataFrame.from_dict(code_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Static Data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "stats_list = []\n",
    "\n",
    "# We have data[node] with a clear data frame\n",
    "if data:\n",
    "    for _, repo in data['code'].iterrows():\n",
    "        # if repo['name'] != 'thefuck':\n",
    "        #    continue\n",
    "        # print(repo)\n",
    "        repoIssues = data['issues'].loc[(data['issues'].owner == repo['owner']) &  (data['issues'].name == repo['name'])]\n",
    "        # print(repoIssues)\n",
    "        repoPulls = data['pulls'].loc[(data['pulls'].owner == repo['owner']) &  (data['pulls'].name == repo['name'])]\n",
    "        # print(repoPulls)\n",
    "        repoCommits = data['commits'].loc[(data['commits'].owner == repo['owner']) &  (data['commits'].name == repo['name'])]\n",
    "        # print(\"Commits:\", repoCommits[['committedDate']].values)\n",
    "\n",
    "        ############################# POPULARITY ####################################\n",
    "        popularity_list = []\n",
    "\n",
    "        # How many open pull requests are there?\n",
    "        openPullsQty = repoPulls.loc[repoPulls['state'] == 'OPEN'].count()['dateTime']\n",
    "        # print(\"openPullsQty:\", openPullsQty)\n",
    "        p = popularity_calc_pulls(openPullsQty)\n",
    "        popularity_list.append(p)\n",
    "\n",
    "        # How many open issues are there?\n",
    "        open_issues_qty = repoIssues.loc[repoIssues['state'] == 'OPEN'].count()['dateTime']\n",
    "        # print(\"open issuesQty:\", open_issues_qty)\n",
    "        p = popularity_calc_issues(open_issues_qty)\n",
    "        popularity_list.append(p)\n",
    "\n",
    "        # How many contributors does the project have?\n",
    "        participantsTotalCount = repoIssues['participants.totalCount'].astype(int).sum()\n",
    "        # print(\"participantsTotalCount:\", participantsTotalCount)\n",
    "        p = popularity_calc_contribution(participantsTotalCount)\n",
    "        popularity_list.append(p)\n",
    "\n",
    "        print(popularity_list)\n",
    "        popularity = average(popularity_list)\n",
    "        # print(\"Popularity:\", popularity)\n",
    "        # print('##########################')\n",
    "\n",
    "\n",
    "        ############################# FREQUENCY ####################################\n",
    "        frequency_list = []\n",
    "        # When was the latest commit?\n",
    "        f = frequency_calc_score(repoCommits[['committedDate']].values, 'commitFrequency' )\n",
    "        frequency_list.append(f)\n",
    "\n",
    "        # Are the issues recent?\n",
    "        f = frequency_calc_score(repoIssues[['createdAt']].values, 'issuesRecent' )\n",
    "        frequency_list.append(f)\n",
    "\n",
    "        # Are issues getting closed?\n",
    "        f = frequency_calc_score(repoIssues.loc[repoIssues['state'] == 'CLOSED'][['closedAt']].values, 'issuesGettingClosed' )\n",
    "        frequency_list.append(f)\n",
    "\n",
    "        # Are issues closed quickly?\n",
    "        issuesClosed = repoIssues.loc[repoIssues['state'] == 'CLOSED']\n",
    "        f = frequency_calc_score_close_time_issue(issuesClosed[['closedAt', 'comments.data']])\n",
    "        frequency_list.append(f)\n",
    "\n",
    "        # Do maintainers respond quickly to issues when they are opened?\n",
    "        f = frequency_calc_score_response_time_issue(repoIssues[['createdAt', 'comments.data']])\n",
    "        frequency_list.append(f)\n",
    "\n",
    "        # Do maintainers respond quickly to pull requests when they are opened?\n",
    "        # print(repoPulls[['createdAt', 'comments.data']])\n",
    "        f = frequency_calc_score_response_time_pull(repoPulls[['createdAt', 'comments.data']])\n",
    "        frequency_list.append(f)\n",
    "\n",
    "        # Are the pull requests recent?\n",
    "        f = frequency_calc_score(repoPulls[['createdAt']].values, 'pullsRecent' )\n",
    "        frequency_list.append(f)\n",
    "\n",
    "        # How recently were any pull requests merged?\n",
    "        f = frequency_calc_score(repoPulls.loc[repoPulls['state'] == 'MERGED'][['mergedAt']].values, 'pullsGettingMerged' )\n",
    "        frequency_list.append(f)\n",
    "\n",
    "        frequency = average(frequency_list)\n",
    "        # print(\"Frequency:\", frequency)\n",
    "        # print('##########################')\n",
    "\n",
    "\n",
    "        ############################# DEFINITION OOS ####################################\n",
    "        definitionOSS = definition_oos_calc(repo)\n",
    "        # print(definitionOSS)\n",
    "\n",
    "        ############################# QUALITY ####################################\n",
    "        quality = 0.5\n",
    "\n",
    "        ############################# FRIENDLY ####################################\n",
    "        friendly = 0.5\n",
    "\n",
    "\n",
    "        stats = {\n",
    "            'frequency': round(frequency, 2),\n",
    "            'definitionOSS': round(definitionOSS, 2),\n",
    "            'popularity': round(popularity, 2),\n",
    "            'friendly': round(friendly, 2),\n",
    "            'quality': round(quality, 2),\n",
    "            'name': repo['name'],\n",
    "            'owner': repo['owner'],\n",
    "            'provider': provider,\n",
    "            'language': repo['languages']\n",
    "        }\n",
    "        stats_list.append(stats)\n",
    "\n",
    "        df = pd.DataFrame(dict(\n",
    "            r=[frequency, definitionOSS, 5, popularity, 5],\n",
    "            theta=['Frequency','Definition of OSS','Friendly',\n",
    "                   'Popularity', 'Quality']))\n",
    "        fig = px.line_polar(df, r='r', theta='theta', line_close=True)\n",
    "        fig.update_layout(\n",
    "            title = repo['owner'] + '/' + repo['name'],\n",
    "            polar=dict(\n",
    "                radialaxis=dict(\n",
    "                visible=True,\n",
    "                  range=[0, 101]\n",
    "                )),\n",
    "            showlegend=False\n",
    "        )\n",
    "        fig.show()\n",
    "        # break\n",
    "\n",
    "    sr = save_data(provider, stats_list)\n",
    "    print(sr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Analysis\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}