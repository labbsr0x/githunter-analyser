{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import requests\n",
    "import json\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from numpy import ones,vstack\n",
    "from numpy.linalg import lstsq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% imports\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "provider = \"github\"\n",
    "nodes = ['pulls', 'issues', 'commits']\n",
    "save_node = \"repositoryStats\"\n",
    "# nodes = ['pulls', 'issues']\n",
    "start_date = '2019-09-01T00:00:00-03:00'\n",
    "end_date = '2021-09-15T23:59:59-03:00'\n",
    "\n",
    "date_format = '%Y-%m-%dT%H:%M:%S%z'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% params\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def save_data(_provider, _data_api_params):\n",
    "    _data_api_url = f'http://localhost:3005/publish/provider/'+ _provider + '/node/' + save_node + '?createRawData=true'\n",
    "    _data_api_headers = {\n",
    "        'content-type': 'application/json'\n",
    "    }\n",
    "    _data_api_request = requests.post(_data_api_url, json=_data_api_params, headers=_data_api_headers)\n",
    "    _data = json.loads(_data_api_request.text)\n",
    "    return _data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% save data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def load_data(_provider, _node, _start_date, _end_date):\n",
    "    _data_api_url = f'http://localhost:3005/metrics'\n",
    "    _data_api_params = {\n",
    "        'startDateTime': _start_date,\n",
    "        'endDateTime': _end_date,\n",
    "        'provider': _provider,\n",
    "        'node': _node\n",
    "    }\n",
    "    _data_api_headers = {\n",
    "        'content-type': 'application/json'\n",
    "    }\n",
    "    _data_api_request = requests.get(_data_api_url, params=_data_api_params, headers=_data_api_headers)\n",
    "    if _data_api_request.status_code == 200:\n",
    "        _data = json.loads(_data_api_request.text)\n",
    "        # data_source = json.dumps(data, indent=4, sort_keys=True)\n",
    "        return _data['data']\n",
    "    return []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% request data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def load_mongo_data(_repo_list):\n",
    "    _data_api_url = f'http://localhost:3333/code-info'\n",
    "    _data_api_params = {\n",
    "        'repoList': _repo_list\n",
    "    }\n",
    "    print(_data_api_params)\n",
    "    _data_api_headers = {\n",
    "        'content-type': 'application/json'\n",
    "    }\n",
    "    _data_api_request = requests.get(_data_api_url, json=_data_api_params, headers=_data_api_headers)\n",
    "    _data = json.loads(_data_api_request.text)\n",
    "    # _data_source = json.dumps(_data, indent=4, sort_keys=True)\n",
    "    if 'data' in _data:\n",
    "        return _data['data']\n",
    "    elif 'repositories' in _data:\n",
    "        return _data['repositories']\n",
    "    return _data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% request Mongo data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    # frequency\n",
    "    \"commitFrequency\": [[366,0], [168,40], [48,60], [6,100]],\n",
    "    \"issuesRecent\": [[720,0],[360,20],[160,50],[48,80],[24,100]],\n",
    "    \"issuesGettingClosed\": [[720,0], [360,40], [160,80], [72,100]],\n",
    "    \"issuesClosedQuickly\": [[720,0], [504,40], [240,60], [120,100]],\n",
    "    \"issuesResponseQuickly\": [[336,0], [168,40], [48,50], [24,80],[2,100]],\n",
    "    \"pullsResponseQuickly\": [[336,0], [168,40], [48,50], [24,80],[2,100]],\n",
    "    \"pullsRecent\": [[720,0],[360,20],[160,50],[48,80],[24,100]],\n",
    "    \"pullsGettingMerged\": [[720,0], [360,40], [160,80], [72,100]],\n",
    "\n",
    "    #definition oos\n",
    "    \"readmeFileSize\": [[0,0], [3500,100]],\n",
    "\n",
    "    # popularity\n",
    "    \"numberOfContributors\": [[1,0], [50,30] ,[100,70], [200,100]],\n",
    "    \"numberOfIssues\": [[1,0], [50,30] ,[100,70], [200,100]],\n",
    "    \"numberOfPulls\": [[1,0], [50,30] ,[100,70], [200,100]]\n",
    "}\n",
    "\n",
    "def format_date(_date_string):\n",
    "    _date_obj = datetime.datetime.strptime(_date_string, date_format)\n",
    "    return _date_obj\n",
    "\n",
    "def average(_list):\n",
    "    if len(_list) > 0:\n",
    "        return sum(_list) / len(_list)\n",
    "    return 0\n",
    "\n",
    "def get_metric_percent(_metric, _value):\n",
    "    _btw_index = -1 # Last array position\n",
    "    for i, v in enumerate(metrics[_metric]):\n",
    "        if _value >= v[0]:\n",
    "            _btw_index = i\n",
    "            break\n",
    "    if _btw_index == 0:\n",
    "        return metrics[_metric][0][1] # returning minimal score\n",
    "    elif _btw_index == -1:\n",
    "        return metrics[_metric][-1][1] # returning maximal score\n",
    "\n",
    "    _point_0 = (metrics[_metric][i-1][0], metrics[_metric][i-1][1])\n",
    "    _point_1 = (metrics[_metric][i][0], metrics[_metric][i][1])\n",
    "    _points = [_point_0,_point_1]\n",
    "    _x_coords, _y_coords = zip(*_points)\n",
    "    _A = vstack([_x_coords,ones(len(_x_coords))]).T\n",
    "    _x, _c = lstsq(_A, _y_coords)[0]\n",
    "\n",
    "    _score = _x * _value + _c\n",
    "\n",
    "    return _score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Calculation Utils\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def calc_frequency(_list):\n",
    "#     sort by date\n",
    "#     print(_list)\n",
    "    if len(_list) == 0:\n",
    "        return 0\n",
    "    _frequency = 0\n",
    "    for index, value in enumerate(_list):\n",
    "        if index == 0:\n",
    "            _date_a = datetime.datetime.now().replace(tzinfo=datetime.timezone.utc).astimezone(tz=None)\n",
    "        else:\n",
    "            _date_a = format_date(_list[index-1][0])\n",
    "        _date_b = format_date(_list[index][0])\n",
    "        _delta = _date_a - _date_b\n",
    "        if _delta.total_seconds() < 0:\n",
    "            _delta = _date_b - _date_a\n",
    "        # print(\"Delta: \",_date_a, _date_b, _delta)\n",
    "        _frequency = _frequency + _delta.total_seconds()\n",
    "    _frequency = (_frequency/len(_list)) / 60 / 60\n",
    "    return _frequency\n",
    "\n",
    "def frequency_calc_score(_list, _metric):\n",
    "    _frequency = calc_frequency(_list)\n",
    "    _score = get_metric_percent(_metric, _frequency)\n",
    "    return _score\n",
    "\n",
    "def frequency_calc_score_close_time_issue(_list_of_dict):\n",
    "    _comments = _list_of_dict['comments.data']\n",
    "    _frequency = []\n",
    "    for _i, _c in _comments.items():\n",
    "        if not _c:\n",
    "            continue\n",
    "        _closed_at = _list_of_dict['closedAt'].get(_i)\n",
    "        _sorted = sorted(_c, key=lambda x: format_date(x['createdAt']), reverse=True)\n",
    "        for _s in _sorted:\n",
    "            _diff = format_date(_closed_at) - format_date(_s['createdAt'])\n",
    "            # sometime the user say thanks then close the issue\n",
    "            if _diff.total_seconds() >= 30:\n",
    "                break\n",
    "        _score = get_metric_percent('issuesClosedQuickly', (_diff.total_seconds() / 60 / 60))\n",
    "        _frequency.append(_score)\n",
    "    return average(_frequency)\n",
    "\n",
    "def frequency_calc_score_response_time_issue(_list_of_dict):\n",
    "    _comments = _list_of_dict['comments.data']\n",
    "    _frequency = []\n",
    "    for _i, _c in _comments.items():\n",
    "        if not _c:\n",
    "            continue\n",
    "        _created_at = _list_of_dict['createdAt'].get(_i)\n",
    "        _sorted = sorted(_c, key=lambda x: format_date(x['createdAt']))\n",
    "        for _s in _sorted:\n",
    "            _diff = format_date(_created_at) - format_date(_s['createdAt'])\n",
    "            # sometime the user say thanks then close the issue\n",
    "            if _diff.total_seconds() >= 30:\n",
    "                break\n",
    "        _score = get_metric_percent('issuesResponseQuickly', (_diff.total_seconds() / 60 / 60))\n",
    "        _frequency.append(_score)\n",
    "    return average(_frequency)\n",
    "\n",
    "def frequency_calc_score_response_time_pull(_list_of_dict):\n",
    "    _comments = _list_of_dict['comments.data']\n",
    "    _frequency = []\n",
    "    for _i, _c in _comments.items():\n",
    "        if not _c:\n",
    "            continue\n",
    "        _created_at = _list_of_dict['createdAt'].get(_i)\n",
    "        _sorted = sorted(_c, key=lambda x: format_date(x['createdAt']))\n",
    "        for _s in _sorted:\n",
    "            _diff = format_date(_created_at) - format_date(_s['createdAt'])\n",
    "            # sometime the user say thanks then close the issue\n",
    "            if _diff.total_seconds() >= 30:\n",
    "                break\n",
    "        _score = get_metric_percent('issuesResponseQuickly', (_diff.total_seconds() / 60 / 60))\n",
    "        _frequency.append(_score)\n",
    "    return average(_frequency)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Calculation Frequency Score\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def definition_oos_calc(_repo):\n",
    "    _definitionOSS = []\n",
    "\n",
    "    # Does it have a license?\n",
    "    if _repo['licenseInfo'] != \"\":\n",
    "        _definitionOSS.append(100)\n",
    "    else:\n",
    "        _definitionOSS.append(0)\n",
    "\n",
    "    # Does it have a Readme? Check the size (reference size repo Docker)\n",
    "    if _repo['hasReadmeFile']:\n",
    "        _score = 100\n",
    "        if not numpy.isnan(_repo['readmeFileSize']):\n",
    "            _score = get_metric_percent(\"readmeFileSize\", _repo['readmeFileSize'])\n",
    "        _definitionOSS.append(_score)\n",
    "    else:\n",
    "        _definitionOSS.append(0)\n",
    "\n",
    "    # Does it have a Contribution?\n",
    "    if _repo['hasContributingFile']:\n",
    "        _definitionOSS.append(70)\n",
    "    else:\n",
    "        _definitionOSS.append(30)\n",
    "\n",
    "    # Does it have a Code of Conduct?\n",
    "    if _repo['hasCodeOfConductFile']:\n",
    "        _definitionOSS.append(70)\n",
    "    else:\n",
    "        _definitionOSS.append(30)\n",
    "\n",
    "    return average(_definitionOSS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Calculation Definition OOS Score\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def popularity_calc_contribution(_qty):\n",
    "    _score = get_metric_percent(\"numberOfContributors\", _qty)\n",
    "    return _score\n",
    "\n",
    "def popularity_calc_issues(_qty):\n",
    "    _score = get_metric_percent(\"numberOfIssues\", _qty)\n",
    "    return _score\n",
    "\n",
    "def popularity_calc_pulls(_qty):\n",
    "    _score = get_metric_percent(\"numberOfPulls\", _qty)\n",
    "    return _score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Calculation Popularity Score\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "data = {}\n",
    "for node in nodes:\n",
    "    raw_data = load_data(provider, node, start_date, end_date)\n",
    "    # Keeping last version of itens\n",
    "    if node in 'commits':\n",
    "        data[node] = pd.DataFrame.from_dict(pd.json_normalize(raw_data))\n",
    "    else:\n",
    "        data[node] = pd.DataFrame.from_dict(pd.json_normalize(raw_data)).sort_values('dateTime').groupby('number').tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% StarWS Data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        dateTime  number   state             createdAt  \\\n",
      "205   2019-09-19T12:03:10.00072Z     245  MERGED  2020-10-11T02:12:06Z   \n",
      "2    2019-10-01T20:44:31.000322Z     301    OPEN  2020-09-13T07:09:56Z   \n",
      "1    2019-10-02T17:11:09.000606Z       9  MERGED  2020-09-09T13:13:54Z   \n",
      "206   2019-10-16T10:23:18.00095Z       6  MERGED  2019-09-16T23:17:25Z   \n",
      "223  2019-10-26T05:01:11.000707Z      78    OPEN  2020-01-24T04:25:20Z   \n",
      "..                           ...     ...     ...                   ...   \n",
      "177  2020-12-23T02:00:38.000693Z    1842    OPEN  2020-12-22T22:38:10Z   \n",
      "92    2020-12-23T02:02:42.00019Z     348    OPEN  2020-11-12T21:48:59Z   \n",
      "90   2020-12-23T02:02:42.000352Z      91    OPEN  2020-12-19T18:13:18Z   \n",
      "89   2020-12-23T02:02:42.000781Z     469  MERGED  2020-12-18T06:34:26Z   \n",
      "91   2020-12-23T02:02:42.000952Z     465  MERGED  2020-12-17T06:32:01Z   \n",
      "\n",
      "                 closedAt  merged              mergedAt              author  \\\n",
      "205  2020-10-11T08:23:06Z    True  2020-10-11T08:23:06Z          dependabot   \n",
      "2                           False                                Ice3man543   \n",
      "1    2020-09-23T15:37:43Z    True  2020-09-23T15:37:43Z       abluidesigner   \n",
      "206  2019-09-19T12:03:10Z    True  2019-09-19T12:03:10Z  monkeywithacupcake   \n",
      "223                         False                              JimmyCushnie   \n",
      "..                    ...     ...                   ...                 ...   \n",
      "177                         False                                KOQITFREAK   \n",
      "92                          False                                    muesli   \n",
      "90                          False                              mehmetcantas   \n",
      "89   2020-12-18T06:35:46Z    True  2020-12-18T06:35:46Z          dependabot   \n",
      "91   2020-12-17T07:05:32Z    True  2020-12-17T07:05:32Z          dependabot   \n",
      "\n",
      "                   labels                                            rawData  \\\n",
      "205        [dependencies]  http://localhost:4455/json-data-api/v1/datajso...   \n",
      "2    [Type: Optimization]  http://localhost:4455/json-data-api/v1/datajso...   \n",
      "1                    None  http://localhost:4455/json-data-api/v1/datajso...   \n",
      "206                  None  http://localhost:4455/json-data-api/v1/datajso...   \n",
      "223                  None  http://localhost:4455/json-data-api/v1/datajso...   \n",
      "..                    ...                                                ...   \n",
      "177                  None  http://localhost:4455/json-data-api/v1/datajso...   \n",
      "92                   None  http://localhost:4455/json-data-api/v1/datajso...   \n",
      "90                   None  http://localhost:4455/json-data-api/v1/datajso...   \n",
      "89     [dependencies, go]  http://localhost:4455/json-data-api/v1/datajso...   \n",
      "91     [dependencies, go]  http://localhost:4455/json-data-api/v1/datajso...   \n",
      "\n",
      "    owner name provider  type             updatedAt  participants.totalCount  \\\n",
      "205              github  pull  2020-10-11T08:23:17Z                        1   \n",
      "2                github  pull  2020-09-17T08:46:10Z                        1   \n",
      "1                github  pull  2020-09-23T15:37:43Z                        2   \n",
      "206              github  pull  2019-09-19T12:03:10Z                        2   \n",
      "223              github  pull  2020-04-06T17:40:51Z                        3   \n",
      "..    ...  ...      ...   ...                   ...                      ...   \n",
      "177              github  pull  2020-12-22T22:38:10Z                        1   \n",
      "92               github  pull  2020-12-23T02:02:42Z                        1   \n",
      "90               github  pull  2020-12-19T18:13:18Z                        1   \n",
      "89               github  pull  2020-12-18T06:35:47Z                        1   \n",
      "91               github  pull  2020-12-17T07:11:25Z                        1   \n",
      "\n",
      "                        participants.users  \\\n",
      "205                                [ly525]   \n",
      "2                             [Ice3man543]   \n",
      "1             [abluidesigner, abuanwar072]   \n",
      "206         [monkeywithacupcake, yanglbme]   \n",
      "223  [JimmyCushnie, syedsuhaib, dmitryvhf]   \n",
      "..                                     ...   \n",
      "177                           [KOQITFREAK]   \n",
      "92                                [muesli]   \n",
      "90                          [mehmetcantas]   \n",
      "89                                 [gabek]   \n",
      "91                                 [gabek]   \n",
      "\n",
      "                                         comments.data  comments.totalCount  \\\n",
      "205                                               None                    0   \n",
      "2                                                 None                    0   \n",
      "1                                                 None                    0   \n",
      "206                                               None                    0   \n",
      "223                                               None                    0   \n",
      "..                                                 ...                  ...   \n",
      "177                                               None                    0   \n",
      "92                                                None                    0   \n",
      "90                                                None                    0   \n",
      "89                                                None                    0   \n",
      "91   [{'author': 'gabek', 'createdAt': '2020-12-17T...                    1   \n",
      "\n",
      "    comments.updatedAt  \n",
      "205                     \n",
      "2                       \n",
      "1                       \n",
      "206                     \n",
      "223                     \n",
      "..                 ...  \n",
      "177                     \n",
      "92                      \n",
      "90                      \n",
      "89                      \n",
      "91                      \n",
      "\n",
      "[279 rows x 20 columns]\n",
      "                        dateTime  number   state             createdAt  \\\n",
      "0    2019-10-19T21:11:12.000784Z      73    OPEN  2019-12-02T22:55:30Z   \n",
      "154  2019-10-27T04:22:31.000686Z      90    OPEN  2020-11-17T15:28:02Z   \n",
      "151  2019-11-07T08:28:19.000666Z     273    OPEN  2020-11-23T09:10:25Z   \n",
      "150  2020-01-03T01:01:05.000842Z     369  CLOSED  2020-08-05T05:23:42Z   \n",
      "198  2020-02-01T12:14:35.000021Z      79    OPEN  2020-02-05T19:02:53Z   \n",
      "..                           ...     ...     ...                   ...   \n",
      "22    2020-12-23T01:17:43.00061Z     500  CLOSED  2020-12-22T17:55:50Z   \n",
      "89   2020-12-23T01:41:40.000612Z      24    OPEN  2020-12-22T18:06:12Z   \n",
      "16   2020-12-23T01:43:35.000503Z     492    OPEN  2020-12-22T05:21:25Z   \n",
      "79   2020-12-23T01:55:01.000989Z      33    OPEN  2020-12-22T00:57:47Z   \n",
      "80   2020-12-23T01:57:09.000415Z      37  CLOSED  2020-12-22T20:18:11Z   \n",
      "\n",
      "                 closedAt             updatedAt        author  \\\n",
      "0                          2020-04-18T16:19:22Z         boop5   \n",
      "154                        2020-11-17T15:28:02Z    TIcha-Toey   \n",
      "151                        2020-11-23T09:10:25Z     564602391   \n",
      "150  2020-08-08T02:46:35Z  2020-08-08T02:46:35Z  ajrhowarthpt   \n",
      "198                        2020-02-05T19:02:53Z     ofirbarak   \n",
      "..                    ...                   ...           ...   \n",
      "22   2020-12-22T18:28:07Z  2020-12-22T18:38:55Z      jeyemwey   \n",
      "89                         2020-12-22T18:06:12Z   xXNicksonXx   \n",
      "16                         2020-12-22T19:06:08Z   johanfleury   \n",
      "79                         2020-12-22T22:20:28Z    TimMHunter   \n",
      "80   2020-12-22T22:16:34Z  2020-12-22T22:16:34Z     nocxtious   \n",
      "\n",
      "                                    labels  \\\n",
      "0                                     None   \n",
      "154                                   None   \n",
      "151                                   None   \n",
      "150                                   None   \n",
      "198                                   None   \n",
      "..                                     ...   \n",
      "22   [Web frontend, bug, good first issue]   \n",
      "89                                    None   \n",
      "16                                    None   \n",
      "79                                   [bug]   \n",
      "80                                    None   \n",
      "\n",
      "                                               rawData owner name provider  \\\n",
      "0    http://localhost:4455/json-data-api/v1/datajso...              github   \n",
      "154  http://localhost:4455/json-data-api/v1/datajso...              github   \n",
      "151  http://localhost:4455/json-data-api/v1/datajso...              github   \n",
      "150  http://localhost:4455/json-data-api/v1/datajso...              github   \n",
      "198  http://localhost:4455/json-data-api/v1/datajso...              github   \n",
      "..                                                 ...   ...  ...      ...   \n",
      "22   http://localhost:4455/json-data-api/v1/datajso...              github   \n",
      "89   http://localhost:4455/json-data-api/v1/datajso...              github   \n",
      "16   http://localhost:4455/json-data-api/v1/datajso...              github   \n",
      "79   http://localhost:4455/json-data-api/v1/datajso...              github   \n",
      "80   http://localhost:4455/json-data-api/v1/datajso...              github   \n",
      "\n",
      "       type  participants.totalCount                       participants.users  \\\n",
      "0    issues                        3            [boop5, tiagossa1, dmitryvhf]   \n",
      "154  issues                        1                             [TIcha-Toey]   \n",
      "151  issues                        1                              [564602391]   \n",
      "150  issues                        2                   [nwtgck, ajrhowarthpt]   \n",
      "198  issues                        1                              [ofirbarak]   \n",
      "..      ...                      ...                                      ...   \n",
      "22   issues                        4  [gabek, jeyemwey, SeaLife, gingervitis]   \n",
      "89   issues                        1                            [xXNicksonXx]   \n",
      "16   issues                        1                            [johanfleury]   \n",
      "79   issues                        3      [mafiesto4, jb-perrier, TimMHunter]   \n",
      "80   issues                        1                              [nocxtious]   \n",
      "\n",
      "                                         comments.data  comments.totalCount  \\\n",
      "0    [{'author': 'dmitryvhf', 'createdAt': '2020-01...                    2   \n",
      "154                                               None                    0   \n",
      "151                                               None                    0   \n",
      "150  [{'author': 'nwtgck', 'createdAt': '2020-08-05...                    1   \n",
      "198                                               None                    0   \n",
      "..                                                 ...                  ...   \n",
      "22   [{'author': 'SeaLife', 'createdAt': '2020-12-2...                    3   \n",
      "89                                                None                    0   \n",
      "16   [{'author': 'johanfleury', 'createdAt': '2020-...                    1   \n",
      "79   [{'author': 'jb-perrier', 'createdAt': '2020-1...                    3   \n",
      "80                                                None                    0   \n",
      "\n",
      "    comments.updatedAt  \n",
      "0                       \n",
      "154                     \n",
      "151                     \n",
      "150                     \n",
      "198                     \n",
      "..                 ...  \n",
      "22                      \n",
      "89                      \n",
      "16                      \n",
      "79                      \n",
      "80                      \n",
      "\n",
      "[177 rows x 18 columns]\n",
      "{\"schema\":{\"fields\":[{\"name\":\"owner\",\"type\":\"string\"},{\"name\":\"name\",\"type\":\"string\"}],\"pandas_version\":\"0.20.0\"},\"data\":[{\"owner\":\"\",\"name\":\"\"}]}\n",
      "{'repoList': [{'owner': '', 'name': ''}]}\n"
     ]
    }
   ],
   "source": [
    "# Getting owner and name from all nodes to request data from Mongo\n",
    "frames = []\n",
    "for k in data:\n",
    "    if len(data[k]) > 0:\n",
    "        print(data[k])\n",
    "        frames.append(data[k][['owner', 'name']])\n",
    "\n",
    "result = pd.concat(frames).drop_duplicates().to_json(orient=\"table\", index=None)\n",
    "print(result)\n",
    "repoList = json.loads(result)['data']\n",
    "\n",
    "code_data = load_mongo_data(repoList)\n",
    "data['code'] = pd.DataFrame.from_dict(code_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Static Data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "stats_list = []\n",
    "\n",
    "# We have data[node] with a clear data frame\n",
    "for _, repo in data['code'].iterrows():\n",
    "    # if repo['name'] != 'thefuck':\n",
    "    #     continue\n",
    "    # print(repo)\n",
    "    repoIssues = data['issues'].loc[(data['issues'].owner == repo['owner']) &  (data['issues'].name == repo['name'])]\n",
    "    # print(repoIssues)\n",
    "    repoPulls = data['pulls'].loc[(data['pulls'].owner == repo['owner']) &  (data['pulls'].name == repo['name'])]\n",
    "    # print(repoPulls)\n",
    "    if len(data['commits']) > 0:\n",
    "        repoCommits = data['commits'].loc[(data['commits'].owner == repo['owner']) &  (data['commits'].name == repo['name'])]\n",
    "    # print(\"Commits:\", repoCommits[['committedDate']].values)\n",
    "\n",
    "    ############################# POPULARITY ####################################\n",
    "    popularity_list = []\n",
    "\n",
    "    # How many open pull requests are there?\n",
    "    openPullsQty = repoPulls.loc[repoPulls['state'] == 'OPEN'].count()['dateTime']\n",
    "    # print(\"openPullsQty:\", openPullsQty)\n",
    "    p = popularity_calc_pulls(openPullsQty)\n",
    "    popularity_list.append(p)\n",
    "\n",
    "    # How many open issues are there?\n",
    "    open_issues_qty = repoIssues.loc[repoIssues['state'] == 'OPEN'].count()['dateTime']\n",
    "    # print(\"open issuesQty:\", open_issues_qty)\n",
    "    p = popularity_calc_issues(open_issues_qty)\n",
    "    popularity_list.append(p)\n",
    "\n",
    "    # How many contributors does the project have?\n",
    "    participantsTotalCount = repoIssues['participants.totalCount'].astype(int).sum()\n",
    "    # print(\"participantsTotalCount:\", participantsTotalCount)\n",
    "    p = popularity_calc_contribution(participantsTotalCount)\n",
    "    popularity_list.append(p)\n",
    "\n",
    "    print(popularity_list)\n",
    "    popularity = average(popularity_list)\n",
    "    # print(\"Popularity:\", popularity)\n",
    "    # print('##########################')\n",
    "\n",
    "\n",
    "    ############################# FREQUENCY ####################################\n",
    "    frequency_list = []\n",
    "    # When was the latest commit?\n",
    "    f = frequency_calc_score(repoCommits[['committedDate']].values, 'commitFrequency' )\n",
    "    frequency_list.append(f)\n",
    "\n",
    "    # Are the issues recent?\n",
    "    f = frequency_calc_score(repoIssues[['createdAt']].values, 'issuesRecent' )\n",
    "    frequency_list.append(f)\n",
    "\n",
    "    # Are issues getting closed?\n",
    "    f = frequency_calc_score(repoIssues.loc[repoIssues['state'] == 'CLOSED'][['closedAt']].values, 'issuesGettingClosed' )\n",
    "    frequency_list.append(f)\n",
    "\n",
    "    # Are issues closed quickly?\n",
    "    issuesClosed = repoIssues.loc[repoIssues['state'] == 'CLOSED']\n",
    "    f = frequency_calc_score_close_time_issue(issuesClosed[['closedAt', 'comments.data']])\n",
    "    frequency_list.append(f)\n",
    "\n",
    "    # Do maintainers respond quickly to issues when they are opened?\n",
    "    f = frequency_calc_score_response_time_issue(repoIssues[['createdAt', 'comments.data']])\n",
    "    frequency_list.append(f)\n",
    "\n",
    "    # Do maintainers respond quickly to pull requests when they are opened?\n",
    "    # print(repoPulls[['createdAt', 'comments.data']])\n",
    "    f = frequency_calc_score_response_time_pull(repoPulls[['createdAt', 'comments.data']])\n",
    "    frequency_list.append(f)\n",
    "\n",
    "    # Are the pull requests recent?\n",
    "    f = frequency_calc_score(repoPulls[['createdAt']].values, 'pullsRecent' )\n",
    "    frequency_list.append(f)\n",
    "\n",
    "    # How recently were any pull requests merged?\n",
    "    f = frequency_calc_score(repoPulls.loc[repoPulls['state'] == 'MERGED'][['mergedAt']].values, 'pullsGettingMerged' )\n",
    "    frequency_list.append(f)\n",
    "\n",
    "    frequency = average(frequency_list)\n",
    "    # print(\"Frequency:\", frequency)\n",
    "    # print('##########################')\n",
    "\n",
    "\n",
    "    ############################# DEFINITION OOS ####################################\n",
    "    definitionOSS = definition_oos_calc(repo)\n",
    "    # print(definitionOSS)\n",
    "\n",
    "    ############################# QUALITY ####################################\n",
    "    quality = 0.5\n",
    "\n",
    "    ############################# FRIENDLY ####################################\n",
    "    friendly = 0.5\n",
    "\n",
    "    \n",
    "    stats = {\n",
    "        'frequency': round(frequency, 2),\n",
    "        'definitionOSS': round(definitionOSS, 2),\n",
    "        'popularity': round(popularity, 2),\n",
    "        'friendly': round(friendly, 2),\n",
    "        'quality': round(quality, 2),\n",
    "        'name': repo['name'],\n",
    "        'owner': repo['owner'],\n",
    "        'provider': provider,\n",
    "        'language': repo['languages']\n",
    "    }\n",
    "    stats_list.append(stats)\n",
    "\n",
    "    df = pd.DataFrame(dict(\n",
    "        r=[frequency, definitionOSS, 5, popularity, 5],\n",
    "        theta=['Frequency','Definition of OSS','Friendly',\n",
    "               'Popularity', 'Quality']))\n",
    "    fig = px.line_polar(df, r='r', theta='theta', line_close=True)\n",
    "    fig.update_layout(\n",
    "        title = repo['owner'] + '/' + repo['name'],\n",
    "        polar=dict(\n",
    "            radialaxis=dict(\n",
    "            visible=True,\n",
    "              range=[0, 101]\n",
    "            )),\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.show()\n",
    "    # break\n",
    "\n",
    "print(stats_list)\n",
    "# sr = save_data(provider, stats_list)\n",
    "# print(sr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Analysis\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-36920f3d",
   "language": "python",
   "display_name": "PyCharm (jupyter)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}